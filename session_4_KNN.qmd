---
title: "KNN using `tidymodels`"
author: "Catalina Cañizares, Ph.D. and Raymond Balise Ph.D."
format:
  revealjs:
    scrollable: true
    slide-number: true
    transition: "fade"
    auto-play-media: true
    auto-stretch: true
editor_options: 
  chunk_output_type: console
---


## Agenda 
```{r}
library(tidyverse)
library(tidymodels)
library(skimr)
library(MLearnYRBSS)
```

- Understand the algorithm 
- Review of the math 
- The good and the bad
- `tidymoels` example

## KNN 

- K-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm which can be used for both classification as well as regression predictive problems

- The KNN algorithm assumes that similar things exist in close proximity. 

- Similar things are near to each other.

:::footer
[Machine Learning Basics with the K-Nearest Neighbors Algorithm](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)
:::

## KNN 

Uses ‘feature similarity’ to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.


:::: {.columns}
::: {.column width="50%"}

![](img/knn.png)

:::

::: {.column width="50%"}

![](img/knn2.png)
:::
:::

:::footer
[K-Nearest Neighbors (KNN) Algorithm Tutorial — Machine Learning Basics](https://pub.towardsai.net/k-nearest-neighbors-knn-algorithm-tutorial-machine-learning-basics-ml-ec6756d3e0ac)
:::

## How does it calculate the distance 

**Euclidean distance**

![](img/euclidean_rep.png)

:::footer
[Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)
:::

## KNN

KNN does better than more powerful classifiers and is used in places such as genetics, data compression, and economic forecasting.

- In political science – classing a political voter to “vote Republican” or “vote Democrat”, or to a “will vote” or “will not vote”. 
- Banking system – KNN can be used to predict if a person is fit for loan approval. Or if he or she has similar traits to a defaulter. 

- Calculating credit ratings – KNN can help when calculating an individual’s credit score by comparing it with persons with similar traits. 

:::footer
[A Quick Introduction to KNN Algorithm](https://www.mygreatlearning.com/blog/knn-algorithm-introduction/)

##  Pros and Cons 

:::: {.columns}
::: {.column width="50%"}
**Pros**

- It is straightforward and easy to implement it requires only the k-value parameter

- There are almost no assumptions on the given data. The only thing that is assumed is nearby/similar instances belong to the same category.

- It is a non-parametric approach


:::
::: {.column width="50%"}
**Cons**

- Inefficient for large datasets since distance has to be calculated throughout every point.

- KNN assumes similar data points are close to each other. Therefore, the model is susceptible to outliers.

- It cannot handle imbalanced data. 
:::
:::

:::footer
[K-Nearest Neighbors (KNN) Algorithm Tutorial — Machine Learning Basics](https://pub.towardsai.net/k-nearest-neighbors-knn-algorithm-tutorial-machine-learning-basics-ml-ec6756d3e0ac)
:::

## Task

Predict whether an adolescent has been bullied or not based on a set of various risk behaviors. 

![](https://media.giphy.com/media/iFqLTjlvndks0/giphy.gif)

## Data Cleaning

```{r}
#| echo: true
#| code-line-numbers: "1|3|4|5|6|7"

data("riskyBehaviors")

riskyBehaviors_analysis <- 
  riskyBehaviors |> 
  mutate(Bullying = factor(Bullying)) |> 
  drop_na(Bullying) |> 
  select(- c(SourceAlcohol, SourceVaping, contains("Times"), contains("Days"), CyberBullying))

```


## Splitting the data 

```{r}
#| echo: true
#| code-line-numbers: "1|3|4|6|7|9"
#| output-location: fragment

set.seed(2023)

bullying_split <- initial_split(riskyBehaviors_analysis, 
                               strata = Bullying)

bullying_train <- training(bullying_split)
bullying_test <- testing(bullying_split)

bullying_split
```


## Lets Check Our Work

```{r}
library(janitor)
```


:::: {.columns}
::: {.column width="50%"}

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4"
#| output-location: fragment

bullying_train |> 
  tabyl(Bullying)  |> 
  adorn_pct_formatting(0) |> 
  adorn_totals()



```

:::

::: {.column width="50%"}

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4"
#| output-location: fragment

bullying_test |>  
  tabyl(Bullying)  |> 
  adorn_pct_formatting(0) |> 
  adorn_totals()
```

:::
:::

## The Recipe

```{r}
#| echo: true
#| code-line-numbers: "1|3|4|5|6|7|8|9|10|11"
#| output-location: fragment

library(themis)
# usemodels::use_kknn(Bullying ~ ., data = bullying_train)

bullying_recipe <- 
  recipe(formula = Bullying ~ ., data = bullying_train) |>
  step_downsample(Bullying , under_ratio = 1) |> 
  step_zv(all_predictors()) |> 
  step_normalize(all_numeric_predictors()) |> 
  step_impute_mode(all_nominal_predictors()) |>
  step_impute_mean(all_numeric_predictors()) |> 
  step_dummy(all_nominal_predictors())


```



## The Specification

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4|5"
#| output-location: fragment

kknn_spec <- 
  nearest_neighbor(neighbors = 3) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 

```

## The Workflow

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4|6"
#| output-location: fragment

kknn_workflow <- 
  workflow() %>% 
  add_recipe(bullying_recipe) %>% 
  add_model(kknn_spec) 

kknn_workflow
```


## Fit the model in the training set

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "1|2"
#| output-location: fragment

bullying_fit <- fit(kknn_workflow, bullying_train)
bullying_fit
```

```{r}
#| echo: false
# saveRDS(bullying_fit, "outputs/bullying_fit.rds")
bullying_fit <- readRDS("outputs/bullying_fit.rds")

```

![](https://media.giphy.com/media/yd4RuS9h1YAO4/giphy.gif)

## Checking predictions in the training set

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|5"
#| output-location: fragment
#| eval: false

bullying_pred <- 
  augment(bullying_fit, bullying_train) |> 
  select(Bullying, .pred_class, .pred_1, .pred_0)

bullying_pred
  
```

```{r}
#| echo: false

# saveRDS(bullying_pred, "outputs/bullying_pred.rds")
bullying_pred <- readRDS("outputs/bullying_pred.rds")
bullying_pred
```


## Check the Performance

:::: {.columns}
::: {.column width="50%"}

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4|5|6"
#| output-location: fragment

roc_plot <- 
  bullying_pred |> 
  roc_curve(truth = Bullying, 
           .pred_1, 
           event_level = "second") |> 
  autoplot()

roc_plot

```
:::

::: {.column width="50%"}
```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4"
#| output-location: fragment

bullying_pred |> 
  roc_auc(truth = Bullying, 
           .pred_1, 
           event_level = "second")
```
:::
:::

## Last fit 

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "1|2|3|4|6"
#| output-location: fragment

bullying_last_fit <- 
  last_fit(kknn_workflow, 
           split = bullying_split, 
           metrics = metric_set(kap, roc_auc, sens, spec))

bullying_last_fit 
```

```{r}
#| echo: false

#  saveRDS(bullying_last_fit, "outputs/bullying_last_fit.rds")

bullying_last_fit <- readRDS("outputs/bullying_last_fit.rds")
```

## Metrics in Testing Data 

```{r}
#| echo: true
#| code-line-numbers: "1"
#| output-location: fragment

collect_metrics(bullying_last_fit)
```


## Predictions in the testing set

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|5"
#| output-location: fragment

predictions_testing <- 
  bullying_last_fit |> 
  collect_predictions() |> 
  select(-.row, -.config)

predictions_testing
```



## Make sure your metrics are interpretable
```{r}
#| echo: true
#| code-line-numbers: "1|3|4|5|6"
#| output-location: column

multi_metric <- metric_set(sens, spec, accuracy, kap)

multi_metric(predictions_testing, 
             truth = Bullying, 
             estimate = .pred_class, 
             event_level = "second")
```


:::{.fragment}
![](https://media.giphy.com/media/JHkyBMp6tzceQ/giphy.gif)
:::

## Confusion Matrix in the testing set

```{r}
#| echo: true
#| code-line-numbers: "1|2|3|4|5"
#| output-location: fragment

conf_mat_test <- 
predictions_testing |> 
  conf_mat(Bullying, .pred_class) |> 
  autoplot(type = "heatmap")
conf_mat_test
```


## We did it!

![](https://media.giphy.com/media/9GDMRlL4lqFO0/giphy.gif)



